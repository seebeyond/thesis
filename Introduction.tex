\chapter{Introduction}\label{chapter:introduction}

Online reviews have become in recent years a very important resource for consumers when making purchases. The number of consumers that first read reviews about a product they wish to buy is constantly on the rise. Technology research company Gartner Inc. claims 31\% of consumers read online reviews before actually making a purchase \citet{Gartner2013}. As consumers increasingly rely on these ratings, the incentive for companies to try to produce fake reviews to boost sales is also increasing. Gartner predicts in 2014 as much as 15 percent of all social media reviews will consist of company paid fake reviews, \citet{Gartner2012}. Deceptive reviews have at least two major damaging effects for the consumers. First, they lead the consumer to make bad decisions when buying a product. After reading a bunch of reviews, it might look like a good choice to buy the product, since many users praise it. After, it turns out the product quality is way below expectations and the buyer is disappointed. Second, the consumer's trust in online reviews drops. 

Government regulations and exposure of fake reviews as well as of bad company practices should lead to an increase in the level of trust. Until the proper regulations will be enforced though across markets, some websites are trying to warn users about this practice and publish tips for people to spot fake reviews \citet{TheGuardian2013,Consumerist2010}. Large review websites have even resorted to public shaming to put pressure on businesses who tried to buy reviews to praise their brands. In 2012, Yelp ran its famous "sting" operation when the company displayed a consumer alert message on the profile pages of fraudulent companies. Although this strategy made many headlines, it was stopped after a short time, probably because it became obvious that competitors could actually hurt rival businesses by attempting to buy reviews in their name. 

Another major review website, TripAdvisor has been censured over their claim to offer “honest opinions from real travelers”, when the UK Advertising Standards Authority ruled that the statement was misleading to consumers and that non-genuine content could appear on the website. The company has been recently further shamed by a businessman who registered an imaginary restaurant and then wrote reviews for it. The hoax was detected by TripAdvisor after several months \citet{Forbes2013}.

\section{Problem statement}

Fake reviews come in different "flavors", according to \citet{Jindal2008}. First, there are the non-reviews, or advertisements, that have nothing in common with the actual product being reviewed. Next there are the brand-only reviews which express an opinion about the brand itself or the merchant but do not mention the product. Finally there are untruthful reviews, e.g. spammers writing praising reviews for target shops to boost their overall rating and negative reviews for other shops to damage their reputation. These reviews might be written by individual shop-owners who take advantage of the anonymity luxury to post reviews. Or by individual users that create and maintain many online identities, let them mature and gather credibility so that later on they seem genuine consumers - these users are referred to as sockpuppets. Or by organized groups of users which work together to promote or demote businesses, i.e. group spammers. Each category of spammers presents its own particularities and this makes it very difficult, if not impossible for researchers to design a catch-all model.

There are two directions where the research on opinion spam has focused on so far: behavioral features and text analysis. Behavioral features represent things like the user's rating of a product, the date when the user posted the review, the IP from where the review was posted, how many previous reviews the user made before and so on. Textual analysis refers to methods used to extract clues from the review content, such as the frequency of personal pronouns in the text, or if a high number of predefined suspicious words are used. 

The first method so far seems to be more reliable and can be more easily put into practice. It also offers very good results as a standalone method, although the textual features do bring little overall improvement. This is first of all due to the complexity and hardness of implementing language processing methods in general. The textual analysis techniques have shown less precision on detecting opinion spam, though they improve the overall accuracy when added on top of the behavioral features. The linguistic techniques used so far mostly consisted of computing cosine similarity between the contents of the reviews. In a new study \citet{Zengin2013}, the authors concluded that human judgment used to detect semantic similarity of web document does not correlate well with cosine similarity.

Other researches \citet{Ott2011} used a bag-of-words approach and calculated the frequency of certain words from the review text. They then classified some reviews as suspicious if the text contained a high number of predefined suspicious words. This led to more subjective conclusions that spammers prefer to use more personal pronouns than genuine reviewers or they usually write reviews of more than 150 characters on average. The authors cataloged some words, e.g. "vacation" and "husband" as highly suspicious. They concluded these couple of words appeared more often in the fake reviews created through Amazon Mechanical Turk, but one can hardly say that a review containing the word "vacation" is 100\% fake. An obvious aspect is that once the spammers find out about these textual frequency traps which cause suspicion, they will simply avoid them.

There also seems to be a large gap between the research models on opinion spam following 2008 and the real life scenarios. More precisely, almost all statistics consider only users who write at least 2 reviews and one-time reviewers are eliminated from the reviews datasets. I could find only an exception, \citet{Xie2012} observed that the vast majority of reviewers - more than 90\% in their study of resellerratings.com reviews up to 2010 only write one review. 

I believe this is a much better example of what goes on in real life. What I have seen in my daily work is how much spammers actually prefer to create completely new accounts to post one review, than use an existing account. They have realized how suspicious they become when they write multiple reviews for the same product/company from the same account. This must be the first elementary common sense clue that review platforms use to catch spammers. 

\citet{Xie2012} actually only detect review bursts that indicate possible fraud for reviews being posted in a variable time window, but unfortunately they stop here. In real life, things do not stop here and there are several other steps to pinpoint individual users and reviews as fake. One cannot filter out all the reviews in that time window because there is a high risk honest users will also get penalized. Only some reviews out of the entire batch within the burst are spam, the rest are just innocent bystanders.

It looks like nobody tried to use more advanced text-based models for the problem of detecting fake reviews. For one time reviewers, behavioral clues are scarce, so I believe the key can only be found in the review text. 

\section{Thesis outline}

In chapters \ref{chapter:introduction}, \ref{chapter:goal} and \ref{chapter:relatedwork}, the research problem is defined and motivated and the existing approaches in the literature are reviewed. Section \ref{section:opinion-spam} describes the state-of-the-art research models for the problem of detecting opinion spam. The challenge of computing the similarity between text fragments, as well as the difference between vectorial-based and knowledge-based similarity measures is discussed in sections \ref{section:vectorial-based-measures} and \ref{section:knowledge-based-measures}. The problem of aspect-based opinion mining and ways to use these models for the detection of opinion spam are discussed in section \ref{section:aspect-based-opinion-mining}.

Chapter \ref{chapter:Method} motivates and describes the detection models. In section \ref{section:singleton-detection} a complete method to detect singleton opinion spam is proposed, using density-based clustering algorithms, semantic as well as vectorial-based similarity measures. Improvements to the cosine similarity for measuring textual relatedness are also proposed as well as a new measure aimed to give the best results from both vectorial and semantic methods. 

In section \ref{section:distribution-reviews} a comparison is made between the distributions of truthful and deceptive reviews in two reviews datasets. The first contains only real-life reviews while the second dataset contains truthful reviews from TripAdvisor and deceptive reviews obtained through crowdsourcing. The goal of this experiment is to observe the distribution curves of both types of reviews and measure the distributional gap between them. A secondary objective is to predict how likely the proposed detection models would work on new review datasets.

Section \ref{section:aspect-mining} proposes a method to detect opinion spam, using recent research models aimed at extracting product aspects from short texts, such as user opinions and forums. In recent years, topic modeling and in particular Latent Dirichlet Allocation (LDA) have been proven to work very well for this problem.

Chapter \ref{chapter:Results} presents and discusses the performance of the proposed opinion spam detection models.

Chapter \ref{chapter:discussion} discusses the overall conclusions to be drawn from the methods and results. It suggests possible improvements to the proposed models as well as future research directions.